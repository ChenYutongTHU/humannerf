category: 'human_nerf'
random_seed: 42
#######
experiments:
  color_perturbation: empty #or per-view 
  color_perturbation_strength: strong
  color_perturbation_according_to: camera

##############################################3
## Network Specs

# modules
network_module: 'core.nets.human_nerf.network'
trainer_module: 'core.train.trainers.human_nerf.trainer'
lr_updater_module: 'core.train.trainers.human_nerf.lr_updaters.exp_decay'
optimizer_module: 'core.train.optimizers.human_nerf.optimizer'

# positional embedder -- canonical mlp
embedder:
  module: "core.nets.human_nerf.embedders.fourier"

# learnable embeddings for view directions or T
vocab_embedder:
  module: "core.nets.human_nerf.embedders.vocab_embedder"

# positional embedder -- non-rigid motion mlp
non_rigid_embedder:
  module: "core.nets.human_nerf.embedders.hannw_fourier"

# canonical mlp
canonical_mlp:
  module: 'core.nets.human_nerf.canonical_mlps.mlp_rgb_sigma'
  mlp_depth: 8         # layers in network
  mlp_depth_plus: 0
  mlp_width: 256       # channels per layer
  multires: 10         # log2 of max freq for positional encoding (3D location)
  i_embed: 0           # set 0 for default positional encoding, -1 for none
  view_dir: False
  view_embed: mlp #vocab or mlp
  view_dir_camera_only: False
  view_vocab_n: 4
  view_vocab_dim: 27
  pose_color: wo
  pose_ch: 69
  multires_dir: 4
  last_linear_scale: 1
  condition_code_dim: 0
  condition_code_encoder: none 
  mlpseq:
    hidden_dim: 128
    output_dim: 64
    seq_len: 8
    non_linear: True
    depth: 1
  selfattention:
    hidden_dim: 128
    output_dim: 64
    positional_encoding_type: learnable 
    max_length: 8
  time_input: False 
  time_embed: vocab #vocab or sine
  time_vocab_n: 654 #vocab
  time_dim: 128 #vocab
  multihead:
    enable: False
    head_depth: 1

# motion weights volume
mweight_volume:
  module: 'core.nets.human_nerf.mweight_vol_decoders.deconv_vol_decoder'
  embedding_size: 256
  volume_size: 32
  dst_voxel_size: 0.0625

posevec:
  type: axis_angle
# non-rigid motion mlp
non_rigid_motion_mlp:
  module: 'core.nets.human_nerf.non_rigid_motion_mlps.mlp_offset'
  condition_code_size: 69
  pose_input: True 
  time_input: False 
  time_embed: vocab #vocab or sine
  time_vocab_n: 654 #vocab
  time_vocab_dim: 128 #vocab
  multires_time: 2 #sine
  time_dim:  128 #sine
  mlp_width: 128
  mlp_depth_plus: 0
  mlp_depth: 6
  skips: [4]
  multires: 6       # log2 of max freq for positional encoding (3D location)
  i_embed: 0        # set 0 for default positional encoding, -1 for none
  kick_in_iter: 10000
  full_band_iter: 50000
  last_linear_scale: 1
  multihead:
    enable: False
    head_depth: 1

non_rigid_motion_mlp_sa:
  module: 'core.nets.human_nerf.non_rigid_motion_mlps.mlp_offset_SA'
  sa: 
    version: 1 # or 2 (add&norm, refined pe)
    sa_dim: 128
    condition_embedding: learnable # or sine
    condition_max_length: 4
  condition_code_size: 69
  pose_input: True 
  time_input: False 
  time_embed: vocab #vocab or sine
  time_vocab_n: 654 #vocab
  time_vocab_dim: 128 #vocab
  multires_time: 2 #sine
  time_dim:  128 #sine
  mlp_width: 128
  mlp_depth_plus: 0
  mlp_depth: 5 # 1 for sa
  skips: [4]
  multires: 6       # log2 of max freq for positional encoding (3D location)
  i_embed: 0        # set 0 for default positional encoding, -1 for none
  kick_in_iter: 10000
  full_band_iter: 50000
  last_linear_scale: 1
  multihead:
    enable: False
    head_depth: 1

non_rigid_motion_model: mlp
non_rigid_motion_transformer:
  module: 'core.nets.human_nerf.non_rigid_motion_mlps.transformer_offset'
  d_model: 128
  nhead: 4
  num_encoder_layers: 2
  num_decoder_layers: 2
  dim_feedforward: 256
  joint_embedding: learnable
  time_embedding: learnable # or sine
  time_embedding_max_length: 20
  joint_embedding_max_length: 23
non_rigid_motion_transformer_encoder:
  module: 'core.nets.human_nerf.non_rigid_motion_mlps.transformer_offset'
  d_model: 128
  nhead: 4
  num_encoder_layers: 4
  dim_feedforward: 256
  joint_embedding_type: learnable
  time_embedding_type: learnable # or sine
  time_embedding_max_length: 20
  joint_embedding_max_length: 23
  condition_input_dim: 9
non_rigid_motion_TStransformer_encoder:
  module: 'core.nets.human_nerf.non_rigid_motion_mlps.TStransformer_offset'
  attention_order: TS #or ST
  condition_input_dim: 3 #3 joint/axis-angle, 9 mat
  encoder1: #default temporal
    d_model: 32
    nhead: 1
    num_encoder_layers: 1
    dim_feedforward: 64
    embedding_type: learnable
    embedding_max_length: 4
  encoder2: #default spatial
    d_model: 128
    nhead: 4
    num_encoder_layers: 1
    dim_feedforward: 256
    embedding_type: learnable
    embedding_max_length: 23


# pose decoder
pose_decoder:
  module: 'core.nets.human_nerf.pose_decoders.mlp_delta_body_pose'
  embedding_size: 69
  mlp_width: 256
  mlp_depth: 4
pose_decoder_off: False


##############################################3
## Data Configuration

train_keyfilter: ['rays',
                  'motion_bases', 'motion_weights_priors',
                  'cnl_bbox', 'dst_posevec_69']
test_keyfilter: ['rays', 'target_rgbs', 
                 'motion_bases', 'motion_weights_priors',
                  'cnl_bbox', 'dst_posevec_69']
pose_condition_file: empty
pose_condition_file_cmlp: empty
pose_condition_random_mask: empty
pose_condition_mask_prob: 0.5
eval:
  metrics: ["lpips", "psnr", "ssim"]

train:
  perturb: 1.        # only for training, set to 0. for no jitter, 1. for jitter
  batch_size: 1
  shuffle: True
  drop_last: False
  maxiter: 400000
  lr: 0.0005  # 5e-4
  lr_mweight_vol_decoder: 0.00005 # 5e-5
  lr_pose_decoder: 0.00005        # 5e-5
  lr_non_rigid_mlp: 0.00005       # 5e-5      # 5e-5
  lr_time_embed_fn: 0.00005
  lrate_decay: 500
  optimizer: 'adam'
  log_interval: 20
  save_checkpt_interval: 2000
  save_model_interval: 50000
  ray_shoot_mode: 'patch'
  lossweights:
    lpips: 1.0
    mse: 0.2
    l1: 0.0

test:
  head_id: -1
  weight_threshold: 0.3
  type: skip
  save_3d: False
  save_3d_together: False

train_render:
  batch_size: 1
  shuffle: False
  drop_last: False

progress:
  batch_size: 1
  shuffle: False
  drop_last: False
  dump_interval: 5000

movement:
  batch_size: 1
  shuffle: False
  drop_last: False

novelview:
  batch_size: 1
  shuffle: False
  drop_last: False

novelview_all:
  batch_size: 1
  shuffle: False
  drop_last: False

novelpose:
  batch_size: 1
  shuffle: False
  drop_last: False

novelpose_eval:
  batch_size: 1
  shuffle: False
  drop_last: False

freeview:
  batch_size: 1
  shuffle: False
  drop_last: False
  frame_idx: 0

tpose:
  batch_size: 1
  shuffle: False
  drop_last: False

tpose_pose_condition:
  batch_size: 1
  shuffle: False
  drop_last: False

##############################################3
## Misc

sex: 'neutral'
total_bones: 24
bbox_offset: 0.3

load_net: latest
save_all: True    # save all checkpoints

patch:
  sample_subject_ratio: 0.8
  N_patches: 6
  size: 32      # [Patch] size of patch

N_samples: 128      # number of samples for each ray in coarse ray matching

perturb: 1.        # only for training, set to 0. for no jitter, 1. for jitter

netchunk_per_gpu: 300000 # number of pts sent through network in parallel, decrease if running out of memory
chunk: 32768   # 32768=1024*32, number of rays processed in parallel, decrease if running out of memory
n_gpus: 1

show_alpha: False  
show_truth: False

lpips:
  lpips: True 
  layers: [0,1,2,3,4]

multihead:
  split: view
  head_num: 1
  argmin_cfg:
    selector_criteria: 
      lpips: 1.0
      mse: 0.2
      ssim: 0.0 #
    unselected_lossweights: # for those unselected head
      lpips: 0.0
      mse: 0.0

modules:
  pretrained_path: empty
  canonical_mlp:
    reinit: False
    tune: False
    tune_last: -1
  non_rigid_motion_mlp: 
    reinit: False
    tune: False
  pose_decoder: 
    reinit: False
    tune: False
  mweight_vol_decoder:
    reinit: False
    tune: False

  



